{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# hcho-200M Training on Google Colab\n",
        "\n",
        "Train a 163M parameter language model on Google Colab with GPU acceleration.\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí T4 (free) or V100/A100 (Pro)\n",
        "2. **Run all cells**: Runtime ‚Üí Run all\n",
        "3. **Monitor training**: Watch the progress bars and loss curves\n",
        "\n",
        "## üìä Dataset\n",
        "- **Total tokens**: ~1.1 billion\n",
        "- **Datasets**: WikiText, SQuAD, IMDB, AG News, Yelp, Amazon, GLUE\n",
        "- **Sequence length**: 2048 tokens\n",
        "- **Tokens per parameter**: 6.9 (optimal for training)\n",
        "\n",
        "## ‚è±Ô∏è Training Time\n",
        "- **T4 GPU (free)**: ~3-4 hours\n",
        "- **V100 GPU (Pro)**: ~1-2 hours\n",
        "- **A100 GPU (Pro)**: ~45-60 minutes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA support\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install other dependencies\n",
        "%pip install transformers datasets accelerate tokenizers tqdm pyyaml\n",
        "\n",
        "print(\"‚úÖ Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/your-username/hcho-200M.git\n",
        "%cd hcho-200M\n",
        "\n",
        "print(\"‚úÖ Repository cloned successfully!\")\n",
        "import os\n",
        "print(\"üìÅ Current directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected! Please enable GPU in Runtime settings.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Start Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training with progress monitoring\n",
        "!python train_llm.py --config config.yaml\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
